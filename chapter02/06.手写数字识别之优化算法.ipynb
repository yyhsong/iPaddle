{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b17e48",
   "metadata": {},
   "source": [
    "## 设置学习率\n",
    "\n",
    "- 在神经网络模型中，通常使用标准的随机梯度下降算法更新参数，学习率代表参数更新幅度的大小，即步长。\n",
    "- 当学习率最优时，模型的有效容量最大，最终能达到的效果最好。\n",
    "- 设置合适的学习率需要大量的实验和调参经验：\n",
    "    - 学习率不是越小越好。学习率越小，损失函数的变化速度越慢，意味着需要花费更长的时间进行收敛。\n",
    "    - 学习率不是越大越好。只根据总样本集中的一个批次计算梯度，抽样误差会导致计算出的梯度不是全局最优的方向，且存在波动。在接近最优解时，过大的学习率会导致参数在最优解附近震荡，损失难以收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94011e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import paddle\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea9bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建一个加载数据的迭代器\n",
    "class MnistDataset(paddle.io.Dataset):\n",
    "    def __init__(self, mode):\n",
    "        # 读取原始数据\n",
    "        datafile = '../datasets/mnist.json.gz'\n",
    "        data = json.load(gzip.open(datafile))\n",
    "        \n",
    "        # 划分训练集、验证集和测试集\n",
    "        train_set, valid_set, test_set = data\n",
    "        \n",
    "        # 数据集相关参数：图片宽、高度\n",
    "        self.IMG_ROWS = 28\n",
    "        self.IMG_COLS = 28\n",
    "        \n",
    "        # 拆分数据和标签\n",
    "        if mode=='train':\n",
    "            imgs, labels = train_set[0], train_set[1]\n",
    "        elif mode=='valid':\n",
    "            imgs, labels = valid_set[0], valid_set[1]\n",
    "        elif mode=='test':\n",
    "            imgs, labels = test_set[0], test_set[1]\n",
    "        else:\n",
    "            raise Exception(\"Mode can only be one of ['train', 'valid', 'test']\")\n",
    "                            \n",
    "        # 校验数据\n",
    "        imgs_length = len(imgs)\n",
    "        assert len(imgs) == len(labels), \\\n",
    "            'Length of imgs({}) should be the same as labels({})'.format(len(imgs), len(labels))\n",
    "                            \n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = np.reshape(self.imgs[idx], [1, self.IMG_ROWS, self.IMG_COLS]).astype('float32')\n",
    "        label = np.reshape(self.labels[idx], [1]).astype('int64')\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd0c3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用训练模式，迭代器每次迭代只返回batch=1的数据\n",
    "train_dataset = MnistDataset(mode='train')\n",
    "\n",
    "# 使用paddle.io.DataLoader，返回的是一个批次数据迭代器，并且是异步的\n",
    "train_loader = paddle.io.DataLoader(train_dataset, batch_size=100, shuffle=True, drop_last=True)\n",
    "\n",
    "# 加载验证数据集\n",
    "valid_dataset = MnistDataset(mode='valid')\n",
    "valid_loader = paddle.io.DataLoader(valid_dataset, batch_size=128, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6db0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义多层卷积神经网络\n",
    "class MNIST(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MNIST, self).__init__()\n",
    "\n",
    "        # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "        self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "        self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "        self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "        self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 定义一层全连接层，输出维度是10\n",
    "        self.fc = Linear(in_features=980, out_features=10)\n",
    "        \n",
    "    # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\n",
    "    # 卷积层激活函数使用Relu，全连接层激活函数使用softmax\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = paddle.reshape(x, [x.shape[0], 980])\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "597f80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改计算损失函数\n",
    "def evaluation(model, datasets):\n",
    "    model.eval()\n",
    "    \n",
    "    acc_set = list()\n",
    "    for batch_id, data in enumerate(datasets()):\n",
    "        images, labels = data\n",
    "        images = paddle.to_tensor(images)\n",
    "        labels = paddle.to_tensor(labels)\n",
    "        pred = model(images)\n",
    "        acc = paddle.metric.accuracy(input=pred, label=labels)\n",
    "        acc_set.extend(acc.numpy())\n",
    "    \n",
    "    # 计算多个批次的准确率\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "    return acc_val_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63df37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 学习率的主流优化算法\n",
    "\n",
    "- SGD: 随机梯度下降算法，每次训练少量数据，抽样偏差导致的参数收敛过程中震荡。\n",
    "- Momentum: 每个批次的数据含有抽样误差，导致梯度更新的方向波动较大。引入物理“动量”的概念，累积速度，减少震荡，使参数更新的方向更稳定。\n",
    "- AdaGrad: 根据不同参数距离最优解的远近，动态调整学习率。学习率逐渐下降，依据各参数变化大小调整学习率。\n",
    "- Adam: 由于动量和自适应学习率两个优化思路是正交的，因此可以将这两两个思路结合起来，这就是当前广泛应用的算法。\n",
    "\n",
    "每种优化算法都有特定的参数设置，理论最合理未必在具体案例中最有效，所以模型调参是非常必要的。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    model.train()\n",
    "    \n",
    "    # 四种不同的优化算法\n",
    "    # opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Momentum(learning_rate=0.01, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Adagrad(learning_rate=0.01, parameters=model.parameters())\n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 3\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            # 准备数据\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            # 前向计算的过程\n",
    "            predicts = model(images)\n",
    "            \n",
    "            # 计算损失，使用交叉熵损失函数，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            # 每训练了200批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "            \n",
    "            # 后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            # 最小化loss,更新参数\n",
    "            opt.step()\n",
    "            # 清除梯度\n",
    "            opt.clear_grad()\n",
    "            \n",
    "        acc_train_mean = evaluation(model, train_loader)\n",
    "        acc_valid_mean = evaluation(model, valid_loader)\n",
    "        print('train_acc: {}, valid acc: {}'.format(acc_train_mean, acc_valid_mean))\n",
    "        \n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), '../models/mnist.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dec43c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [4.231844]\n",
      "epoch: 0, batch: 200, loss is: [0.20475605]\n",
      "epoch: 0, batch: 400, loss is: [0.24968132]\n",
      "train_acc: 0.9730600714683533, valid acc: 0.9748597741127014\n",
      "epoch: 1, batch: 0, loss is: [0.12568131]\n",
      "epoch: 1, batch: 200, loss is: [0.10303674]\n",
      "epoch: 1, batch: 400, loss is: [0.05452614]\n",
      "train_acc: 0.9809000492095947, valid acc: 0.9805688858032227\n",
      "epoch: 2, batch: 0, loss is: [0.01553402]\n",
      "epoch: 2, batch: 200, loss is: [0.05573765]\n",
      "epoch: 2, batch: 400, loss is: [0.11679833]\n",
      "train_acc: 0.9834599494934082, valid acc: 0.9803686141967773\n"
     ]
    }
   ],
   "source": [
    "# Init Model\n",
    "model = MNIST()\n",
    "\n",
    "# Start training\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5aa9eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a local image, and convert format to model\n",
    "def load_image(img_path):\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img = img.resize((28, 28))\n",
    "    img = np.array(img).reshape(1, 1, 28, 28).astype(np.float32)\n",
    "    # 图像归一化\n",
    "    img = 1.0 - img / 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cbcb3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别结果： 0\n"
     ]
    }
   ],
   "source": [
    "model = MNIST()\n",
    "model_params_path = '../models/mnist.pdparams'\n",
    "img_path = '../datasets/mnist_example_0.jpg'\n",
    "\n",
    "# Load model's params\n",
    "param_dict = paddle.load(model_params_path)\n",
    "model.load_dict(param_dict)\n",
    "\n",
    "model.eval()\n",
    "tensor_img = load_image(img_path)\n",
    "\n",
    "# 模型返回10个分类标签的对应概率\n",
    "results = model(paddle.to_tensor(tensor_img))\n",
    "\n",
    "# 取出概率最大的标签作为预测输出\n",
    "label = np.argsort(results.numpy())\n",
    "\n",
    "print('识别结果：', label[0][-1])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "无",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
