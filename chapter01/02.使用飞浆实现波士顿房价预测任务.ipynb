{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用飞浆构建神经网络过程\n",
    "\n",
    "- 数据处理：从本地或URL读取数据，并完成预处理操作（如数据校验、格式转换等），保证模型可读取。\n",
    "- 模型设计：网络结构设计，相当于模型的假设空间，即模型能够表达的关系集合。\n",
    "- 训练配置：设定模型采用的寻解算法，即优化器，并指定计算资源。\n",
    "- 训练过程：循环调用训练过程，每轮都包括前向计算、损失函数（优化目标）和后向传播三个步骤。\n",
    "- 模型保存：将训练好的模型保存，模型预测时调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"导入相关的库\n",
    "\n",
    "paddle: 飞浆主库，根目录下保留了常用API的别名，当前包括paddle.tensor, paddle.framework, paddle.device目录下的所有API。\n",
    "paddle.nn: 组网相关的API, 包括Linear, 卷积Conv2D, 循环神经网络LSTM, 损失函数CrossEntropyLoss, 激活函数ReLU等。\n",
    "Linear: 神经网络的全连接层函数，包含所有输入权重相加的基本神经结构。\n",
    "    在本房价预测任务中，使用只有一层的神经网络（全连接层）实现线性回归模型。\n",
    "paddle.nn.functional: 与paddle.nn一样，包含组网相关的API,两者包含的同名模块功能相同，运行性能也基本一致。\n",
    "    差别在于paddle.nn目录下的模块均是类，每个类自带模块参数。\n",
    "    paddle.nn.functional目录下的模块均是函数，需要手动传入函数计算所需要的参数。\n",
    "    在实际使用中，卷积、全连接层等本身具有可学习的参数，建议使用paddle.nn;\n",
    "    而激活函数、池化等操作没有可学习的参数，可以考虑使用paddle.nn.functional。\n",
    "    \n",
    "    \n",
    "飞浆支持两种深度学习建模编写方式，更方便调试的动态图模式和性能更好并便于部署的静态图模式。\n",
    "- 动态图模式（命令式编程范式）：解析式的执行方式。用户无需预先定义完整的网络结构，每写一行网络代码，即可同时获得计算结果。\n",
    "- 静态图模式（声明式编程范式）：先编译后执行的方式。用户需预先定义完整的网络结构，再对网络结构进行编译优化后，才能执行获得计算结果。\n",
    "飞浆默认使用动态图模式进行编码，可通过装饰器（to_static）进行动转静支持，并可保存静态模型以实现推理部署。\n",
    "\"\"\"\n",
    "\n",
    "import paddle\n",
    "from paddle.nn import Linear\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"数据处理不依赖框架实现\"\"\"\n",
    "\n",
    "def load_data():\n",
    "    # 从文件导入数据\n",
    "    data = np.fromfile(r'../datasets/housing.data', sep=' ', dtype=np.float32)\n",
    "    \n",
    "    # 数据形状变换\n",
    "    feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE','DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "    feature_num = len(feature_names)\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\n",
    "    \n",
    "    # 数据集划分\n",
    "    ratio = 0.8\n",
    "    offset = int(data.shape[0] * ratio)\n",
    "    training_data = data[:offset]\n",
    "    \n",
    "    # 归一化处理\n",
    "    maximums = training_data.max(axis=0)\n",
    "    minimums = training_data.min(axis=0)\n",
    "\n",
    "    # 记录数据的归一化参数，在预测时对数据做归一化\n",
    "    global max_values\n",
    "    global min_values\n",
    "    \n",
    "    max_values = maximums\n",
    "    min_values = minimums\n",
    "    \n",
    "    for i in range(feature_num):\n",
    "        data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])\n",
    "        \n",
    "    # 返回训练集和测试集\n",
    "    training_data = data[:offset]\n",
    "    test_data = data[offset:]\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 14)\n",
      "[2.35922547e-04 0.00000000e+00 2.62405723e-01 0.00000000e+00\n",
      " 1.72839552e-01 5.47997713e-01 7.82698274e-01 3.48961979e-01\n",
      " 4.34782617e-02 1.14822544e-01 5.53191364e-01 1.00000000e+00\n",
      " 2.04470202e-01 3.68888885e-01]\n"
     ]
    }
   ],
   "source": [
    "# 验证处理数据程序的正确性\n",
    "training_data, test_data = load_data()\n",
    "print(training_data.shape)\n",
    "print(training_data[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"模型设计\n",
    "\n",
    "模型定义的实质是定义线性回归的网络结构\n",
    "飞浆建议是通过创建类的方式完成模型网络的定义，该类需要继承paddle.nn.Layer父类，并在类中定义init和forward函数。\n",
    "forward函数是框架指定实现前向计算逻辑的函数，程序在调用模型实例时会自动执行，forward函数中使用的网络层需要在init函数中声明。\n",
    "\"\"\"\n",
    "\n",
    "class Regressor(paddle.nn.Layer):\n",
    "    # 在类的初始化函数中声明 每一层网络的实现函数\n",
    "    def __init__(self):\n",
    "        # 初始化父类中的一些参数\n",
    "        super(Regressor, self).__init__()\n",
    "        # 定义一层全连接层，输入维度是13，输出维度是1\n",
    "        self.fc = Linear(in_features=13, out_features=1)\n",
    "        \n",
    "    # 网络的前向计算\n",
    "    def forward(self, inputs):\n",
    "        x = self.fc(inputs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"训练配置的过程\n",
    "\n",
    "1.指定运行训练的机器资源\n",
    "2.声明模型实例\n",
    "3.加载训练和测试数据\n",
    "4.设置优化算法和学习率\n",
    "\n",
    "模型实例有两种状态：训练状态train()和预测状态eval().\n",
    "训练时要执行正向传播和反向传播梯度两个过程，而预测时只需要执行正向计算，为模型指定运行状态，有两点原因：\n",
    "1.部分高级算子在两个状态执行的逻辑不同。\n",
    "2.从性能和存储空间的考虑，预测状态时更节省内存（无需记录反向梯度），性能更好。\n",
    "\"\"\"\n",
    "\n",
    "# 声明定义好的线性回归模型\n",
    "model = Regressor()\n",
    "# 开启模型训练模式\n",
    "model.train()\n",
    "# 加载数据\n",
    "training_data, test_data = load_data()\n",
    "# 指定优化算法 - 随机梯度下降法SGD\n",
    "# 学习率设置为0.01\n",
    "opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 0, loss is: [0.8566502]\n",
      "epoch: 0, iter: 20, loss is: [0.10539891]\n",
      "epoch: 0, iter: 40, loss is: [0.02859592]\n",
      "epoch: 1, iter: 0, loss is: [0.13015077]\n",
      "epoch: 1, iter: 20, loss is: [0.1435532]\n",
      "epoch: 1, iter: 40, loss is: [0.1139743]\n",
      "epoch: 2, iter: 0, loss is: [0.21353555]\n",
      "epoch: 2, iter: 20, loss is: [0.16141763]\n",
      "epoch: 2, iter: 40, loss is: [0.08830484]\n",
      "epoch: 3, iter: 0, loss is: [0.05405422]\n",
      "epoch: 3, iter: 20, loss is: [0.08258742]\n",
      "epoch: 3, iter: 40, loss is: [0.0886056]\n",
      "epoch: 4, iter: 0, loss is: [0.07846634]\n",
      "epoch: 4, iter: 20, loss is: [0.11423707]\n",
      "epoch: 4, iter: 40, loss is: [0.0597805]\n",
      "epoch: 5, iter: 0, loss is: [0.1088708]\n",
      "epoch: 5, iter: 20, loss is: [0.12269257]\n",
      "epoch: 5, iter: 40, loss is: [0.07232613]\n",
      "epoch: 6, iter: 0, loss is: [0.07783701]\n",
      "epoch: 6, iter: 20, loss is: [0.05768992]\n",
      "epoch: 6, iter: 40, loss is: [0.06892546]\n",
      "epoch: 7, iter: 0, loss is: [0.05629098]\n",
      "epoch: 7, iter: 20, loss is: [0.06134908]\n",
      "epoch: 7, iter: 40, loss is: [0.0938561]\n",
      "epoch: 8, iter: 0, loss is: [0.11585684]\n",
      "epoch: 8, iter: 20, loss is: [0.01038083]\n",
      "epoch: 8, iter: 40, loss is: [0.01125065]\n",
      "epoch: 9, iter: 0, loss is: [0.04762356]\n",
      "epoch: 9, iter: 20, loss is: [0.06015943]\n",
      "epoch: 9, iter: 40, loss is: [0.02725614]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"模型训练\n",
    "\n",
    "训练过程采用两层循环嵌套方式：\n",
    "1.内层循环：负责整个数据集的一次遍历，采用分批次方式（batch）。\n",
    "2.外层循环：定义遍历数据集的次数，通过参数EPOCH_NUM设置。\n",
    "\n",
    "batch的取值会影响模型训练效果：\n",
    "batch过大，会增大内存消耗和计算时间，且训练效果并不会明显提升（每次参数只向梯度反方向移动一小步，因此方向没必要特别精确）。\n",
    "batch过小，每个batch的样本数据没有统计意义，计算的梯度方向可能偏差较大。\n",
    "\n",
    "每次内循环需要执行的步骤：\n",
    "1.数据准备：将一个批次的数据先转换成ndarray格式，再转换成Tensor格式；\n",
    "2.前向计算：将一个批次的样本数据灌入网络中，计算输出结果；\n",
    "3.计算损失函数：以前向计算结果和真实房价作为输入，通过损失函数square_error_cost API计算出损失函数值（Loss）；\n",
    "4.反向传播：执行梯度反向传播backward函数，即从后到前逐层计算每一层的梯度，并根据设置的优化算法更新参数（opt.step函数）；\n",
    "\"\"\"\n",
    "\n",
    "# 设置batch大小\n",
    "BATCH_SIZE = 10\n",
    "# 设置外层循环次数\n",
    "EPOCH_NUM = 10\n",
    "\n",
    "# 定义外层循环\n",
    "for epoch_id in range(EPOCH_NUM):\n",
    "    # 在每轮迭代开始之前，将训练数据随机打乱\n",
    "    np.random.shuffle(training_data)\n",
    "    # 将训练数据进行拆分，每个batch包含10条数据\n",
    "    mini_batches = [training_data[k : k+BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]\n",
    "    \n",
    "    # 定义内层循环\n",
    "    for iter_id, mini_batch in enumerate(mini_batches):\n",
    "        # 获得当前批次训练数据\n",
    "        x = np.array(mini_batch[:, :-1])\n",
    "        # 获得当前批次训练标签（真实房价）\n",
    "        y = np.array(mini_batch[:, -1:])\n",
    "        # 将ndarray转换为飞浆动态图tensor的格式\n",
    "        house_features = paddle.to_tensor(x)\n",
    "        prices = paddle.to_tensor(y)\n",
    "        \n",
    "        # 前向计算\n",
    "        predicts = model(house_features)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = F.square_error_cost(predicts, label=prices)\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        if iter_id % 20 == 0:\n",
    "            print('epoch: {}, iter: {}, loss is: {}'.format(epoch_id, iter_id, avg_loss.numpy()))\n",
    "            \n",
    "        # 反向传播，计算每层参数的梯度值\n",
    "        avg_loss.backward()\n",
    "        # 更新参数，根据设置好的学习率迭代一步\n",
    "        opt.step()\n",
    "        # 清空梯度变量，以备下一轮计算\n",
    "        opt.clear_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存并测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"保存并测试模型\n",
    "\n",
    "训练模型和使用模型往往是不同的场景：\n",
    "模型训练通常使用大量的线下服务器\n",
    "模型预测通常使用线上提供预测服务的服务器实现或将已完成的预测模型嵌入到手机或其他终端设备中使用\n",
    "\"\"\"\n",
    "\n",
    "# 保存模型参数\n",
    "paddle.save(model.state_dict(), '../models/paddle_lr_model.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"测试模型\n",
    "\n",
    "测试过程和在应用场景中使用模型的过程一致，主要包括三个步骤：\n",
    "1.配置模型预测的机器资源（本案例默认使用本机，因此无需写代码指定）；\n",
    "2.将训练好的模型参数加载到模型实例中；\n",
    "3.将待预测的样本特征输入到模型中，打印输出的预测结果。\n",
    "\"\"\"\n",
    "\n",
    "# 从测试数据集中抽取一条样本作为测试样本\n",
    "def load_one_example():\n",
    "    # 随机选择一条数据作为测试样本\n",
    "    idx = np.random.randint(0, test_data.shape[0])\n",
    "    one_data, label = test_data[idx, :-1], test_data[idx, -1]\n",
    "    \n",
    "    # 转换数据形状为[1, 13]\n",
    "    one_data = one_data.reshape([1, -1])\n",
    "    \n",
    "    return one_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果为：[[17.519024]], 真实值为：16.799999237060547\n"
     ]
    }
   ],
   "source": [
    "# 加载模型参数\n",
    "model_dict = paddle.load('../models/paddle_lr_model.pdparams')\n",
    "# 将参数加载到模型\n",
    "model.load_dict(model_dict)\n",
    "# 将模型调整为校验状态\n",
    "model.eval()\n",
    "\n",
    "# 加载测试样本\n",
    "one_data, label = load_one_example()\n",
    "# 将数据转为动态图的variable格式\n",
    "one_data = paddle.to_tensor(one_data)\n",
    "# 预测结果\n",
    "predict = model(one_data)\n",
    "\n",
    "# 对结果做反归一化处理\n",
    "predict = predict * (max_values[-1] - min_values[-1]) + min_values[-1]\n",
    "# 对label数据做反归一化处理\n",
    "label = label * (max_values[-1] - min_values[-1]) + min_values[-1]\n",
    "\n",
    "\n",
    "print('预测结果为：{}, 真实值为：{}'.format(predict.numpy(), label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
