{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55ba4de",
   "metadata": {},
   "source": [
    "## 文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5181f61c",
   "metadata": {},
   "source": [
    "### 使用预训练模型进行迁移学习\n",
    "\n",
    "通过高质量预训练模型与PaddleHub Fine-tune API，只需要少量代码即可实现自然语言处理和计算机视觉场景的深度学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b5dd7",
   "metadata": {},
   "source": [
    "### 选择并加载预训练模型\n",
    "\n",
    "使用ERNIE Tiny模型来演示如何利用PaddleHub实现finetune。ERNIE Tiny主要通过模型结构压缩和模型蒸馏的方法，将 ERNIE 2.0 Base 模型进行压缩。相较于 ERNIE 2.0，ERNIE Tiny模型能带来4.3倍的预测提速，具有更高的工业落地能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6747ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\AppData\\Anaconda\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\u001b[32m[2024-02-23 12:53:51,588] [    INFO]\u001b[0m - Already cached C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\model_state.pdparams\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:53:51,589] [    INFO]\u001b[0m - Loading weights file model_state.pdparams from cache at C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\model_state.pdparams\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:53:51,932] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:54:08,007] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing ErnieForSequenceClassification.\n",
      "\u001b[0m\n",
      "\u001b[33m[2024-02-23 12:54:08,008] [ WARNING]\u001b[0m - Some weights of ErnieForSequenceClassification were not initialized from the model checkpoint at ernie-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练模型\n",
    "# Params:\n",
    "# - name         模型名称\n",
    "# - version      模型版本\n",
    "# - task         fine-tune任务，此处seq-cls表示文本分类任务\n",
    "# - num_classes  表示当前文本分类任务的类别数，根据具体使用的数据集确定，默认为2\n",
    "\n",
    "import paddlehub as hub\n",
    "\n",
    "model = hub.Module(name='ernie_tiny', task='seq-cls', num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4dc1bd",
   "metadata": {},
   "source": [
    "### 准备数据集并读取数据\n",
    "\n",
    "此处使用PaddleHub内置的情感分析数据集ChnSentiCorp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197fc9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-02-23 12:54:23,704] [    INFO]\u001b[0m - Already cached C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\vocab.txt\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:54:23,707] [    INFO]\u001b[0m - Already cached C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\spm_cased_simp_sampled.model\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:54:23,709] [    INFO]\u001b[0m - Already cached C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\dict.wordseg.pickle\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:54:28,415] [    INFO]\u001b[0m - tokenizer config file saved in C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:54:28,419] [    INFO]\u001b[0m - Special tokens file saved in C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\special_tokens_map.json\u001b[0m\n",
      "C:\\AppData\\Anaconda\\lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:2293: FutureWarning: The `max_seq_len` argument is deprecated and will be removed in a future version, please use `max_length` instead.\n",
      "  warnings.warn(\n",
      "C:\\AppData\\Anaconda\\lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:1865: UserWarning: Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  warnings.warn(\n",
      "C:\\AppData\\Anaconda\\lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:1878: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\u001b[32m[2024-02-23 12:54:38,461] [    INFO]\u001b[0m - Already cached C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\vocab.txt\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:54:38,463] [    INFO]\u001b[0m - Already cached C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\spm_cased_simp_sampled.model\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:54:38,466] [    INFO]\u001b[0m - Already cached C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\dict.wordseg.pickle\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:54:43,101] [    INFO]\u001b[0m - tokenizer config file saved in C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2024-02-23 12:54:43,105] [    INFO]\u001b[0m - Special tokens file saved in C:\\Users\\Neo\\.paddlenlp\\models\\ernie-tiny\\special_tokens_map.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 自动从网络下载数据集并解压到用户目录下$HUB_HOME/.paddlehub/dataset目录\n",
    "train_dataset = hub.datasets.ChnSentiCorp(tokenizer=model.get_tokenizer(), max_seq_len=128, mode='train')\n",
    "dev_dataset = hub.datasets.ChnSentiCorp(tokenizer=model.get_tokenizer(), max_seq_len=128, mode='dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8761a",
   "metadata": {},
   "source": [
    "### 选择优化策略和运行配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1626752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "\n",
    "\"\"\"优化器\n",
    "\n",
    "优化器：SGD Adam Adamax \n",
    "全局学习率：learning_rate 默认为1e-3\n",
    "待优化模型参数：parameters\n",
    "\"\"\"\n",
    "\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=5e-5, parameters=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76660a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2024-02-23 14:02:00,065] [ WARNING]\u001b[0m - PaddleHub model checkpoint not found, start from scratch...\u001b[0m\n",
      "\u001b[36m[2024-02-23 14:11:19,287] [   TRAIN]\u001b[0m - Epoch=1/1, Step=10/150 loss=0.1617 acc=0.9422 lr=0.000050 step/sec=0.02 | ETA 02:19:48\u001b[0m\n",
      "\u001b[36m[2024-02-23 14:21:13,709] [   TRAIN]\u001b[0m - Epoch=1/1, Step=20/150 loss=0.1411 acc=0.9469 lr=0.000050 step/sec=0.02 | ETA 02:24:12\u001b[0m\n",
      "\u001b[36m[2024-02-23 14:31:21,063] [   TRAIN]\u001b[0m - Epoch=1/1, Step=30/150 loss=0.1463 acc=0.9516 lr=0.000050 step/sec=0.02 | ETA 02:26:44\u001b[0m\n",
      "\u001b[36m[2024-02-23 14:41:12,881] [   TRAIN]\u001b[0m - Epoch=1/1, Step=40/150 loss=0.1438 acc=0.9484 lr=0.000050 step/sec=0.02 | ETA 02:27:03\u001b[0m\n",
      "\u001b[36m[2024-02-23 14:50:40,843] [   TRAIN]\u001b[0m - Epoch=1/1, Step=50/150 loss=0.1227 acc=0.9609 lr=0.000050 step/sec=0.02 | ETA 02:26:02\u001b[0m\n",
      "\u001b[36m[2024-02-23 15:00:25,958] [   TRAIN]\u001b[0m - Epoch=1/1, Step=60/150 loss=0.1208 acc=0.9500 lr=0.000050 step/sec=0.02 | ETA 02:26:04\u001b[0m\n",
      "\u001b[36m[2024-02-23 15:10:21,408] [   TRAIN]\u001b[0m - Epoch=1/1, Step=70/150 loss=0.0963 acc=0.9750 lr=0.000050 step/sec=0.02 | ETA 02:26:28\u001b[0m\n",
      "\u001b[36m[2024-02-23 15:20:47,833] [   TRAIN]\u001b[0m - Epoch=1/1, Step=80/150 loss=0.1525 acc=0.9437 lr=0.000050 step/sec=0.02 | ETA 02:27:44\u001b[0m\n",
      "\u001b[36m[2024-02-23 15:30:56,244] [   TRAIN]\u001b[0m - Epoch=1/1, Step=90/150 loss=0.2348 acc=0.9172 lr=0.000050 step/sec=0.02 | ETA 02:28:13\u001b[0m\n",
      "\u001b[36m[2024-02-23 15:39:49,411] [   TRAIN]\u001b[0m - Epoch=1/1, Step=100/150 loss=0.2747 acc=0.8797 lr=0.000050 step/sec=0.02 | ETA 02:26:44\u001b[0m\n",
      "\u001b[36m[2024-02-23 15:48:43,262] [   TRAIN]\u001b[0m - Epoch=1/1, Step=110/150 loss=0.2358 acc=0.9094 lr=0.000050 step/sec=0.02 | ETA 02:25:31\u001b[0m\n",
      "\u001b[36m[2024-02-23 15:59:19,702] [   TRAIN]\u001b[0m - Epoch=1/1, Step=120/150 loss=0.1848 acc=0.9266 lr=0.000050 step/sec=0.02 | ETA 02:26:39\u001b[0m\n",
      "\u001b[36m[2024-02-23 16:08:53,093] [   TRAIN]\u001b[0m - Epoch=1/1, Step=130/150 loss=0.2086 acc=0.9313 lr=0.000050 step/sec=0.02 | ETA 02:26:24\u001b[0m\n",
      "\u001b[36m[2024-02-23 16:17:36,860] [   TRAIN]\u001b[0m - Epoch=1/1, Step=140/150 loss=0.1719 acc=0.9359 lr=0.000050 step/sec=0.02 | ETA 02:25:17\u001b[0m\n",
      "\u001b[36m[2024-02-23 16:26:43,342] [   TRAIN]\u001b[0m - Epoch=1/1, Step=150/150 loss=0.1645 acc=0.9469 lr=0.000050 step/sec=0.02 | ETA 02:24:43\u001b[0m\n",
      "\u001b[32m[2024-02-23 16:31:17,829] [    INFO]\u001b[0m - Evaluation on validation dataset: |\u001b[0m\r"
     ]
    }
   ],
   "source": [
    "\"\"\"运行配置\n",
    "\n",
    "Trainer主要控制Fine-tune的训练，包含以下可控制的参数:\n",
    "- model: 被优化模型\n",
    "- optimizer: 优化器选择\n",
    "- use_gpu: 是否使用gpu\n",
    "- use_vdl: 是否使用vdl可视化训练过程\n",
    "- checkpoint_dir: 保存模型参数的地址\n",
    "- compare_metrics: 保存最优模型的衡量指标\n",
    "\"\"\"\n",
    "\n",
    "trainer = hub.Trainer(model, optimizer, checkpoint_dir='output/ernie_text_cls')\n",
    "trainer.train(train_dataset, epochs=1, batch_size=64, eval_dataset=dev_dataset, save_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14f02a",
   "metadata": {},
   "source": [
    "### 模型预测\n",
    "\n",
    "当完成Fine-tune后，Fine-tune过程在验证集上表现最优的模型会被保存在`${CHECKPOINT_DIR}/best_model`目录下，其中`${CHECKPOINT_DIR}`目录为Fine-tune时所选择的保存checkpoint的目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587daadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddlehub as hub\n",
    "\n",
    "# 待预测数据\n",
    "data = [\n",
    "    [''],\n",
    "    [''],\n",
    "    ['']\n",
    "]\n",
    "\n",
    "# 预测标签\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "# 加载预训练好的模型\n",
    "model = hub.Module(\n",
    "    name='ernie_tiny',\n",
    "    # version='2.0.1',\n",
    "    task='seq-cls',\n",
    "    load_checkpoint='./output/ernie_text_cls/best_model/model.pdparams',\n",
    "    label_map=label_map\n",
    ")\n",
    "\n",
    "# 模型预测\n",
    "res = model.predict(data, max_seq_len=50, batch_size=1, use_gpu=False)\n",
    "\n",
    "# 打印结果\n",
    "for idx, text in enumerate(data):\n",
    "    print('Text: {} \\t Label: {}'.format(text[0], res[idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
